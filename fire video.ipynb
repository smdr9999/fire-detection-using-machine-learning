{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9394a11c-35b1-4744-8035-7222d3a1f83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygame\n",
      "  Obtaining dependency information for pygame from https://files.pythonhosted.org/packages/82/61/93ae7afbd931a70510cfdf0a7bb0007540020b8d80bc1d8762ebdc46479b/pygame-2.5.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading pygame-2.5.2-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Downloading pygame-2.5.2-cp311-cp311-win_amd64.whl (10.8 MB)\n",
      "   ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/10.8 MB 4.2 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.4/10.8 MB 5.8 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.7/10.8 MB 5.5 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/10.8 MB 5.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.2/10.8 MB 5.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.3/10.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/10.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/10.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.8/10.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.1/10.8 MB 4.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.3/10.8 MB 4.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.5/10.8 MB 4.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.7/10.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/10.8 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.1/10.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.3/10.8 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.4/10.8 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.6/10.8 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.6/10.8 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.6/10.8 MB 4.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.2/10.8 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.3/10.8 MB 4.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.6/10.8 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.8/10.8 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.9/10.8 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.1/10.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.3/10.8 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.5/10.8 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.7/10.8 MB 4.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.9/10.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.1/10.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.2/10.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.3/10.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.5/10.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.7/10.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.9/10.8 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.1/10.8 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.2/10.8 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.5/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.6/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.8/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.0/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.2/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.4/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.5/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.8/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.9/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.1/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.3/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.5/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.7/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.9/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.1/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.3/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.4/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.5/10.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/10.8 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/10.8 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.8/10.8 MB 3.9 MB/s eta 0:00:00\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a5e6e5-6a18-4ba4-b74e-a31749efeaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Fire Caught - Emergency!\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict_image(model, img):\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize the pixel values\n",
    "    prediction = model.predict(img_array)\n",
    "    return prediction[0][0]\n",
    "\n",
    "def process_video(video_path, model):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Set the frame rate\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(fps * 3)  # Capture a frame every 3 seconds\n",
    "\n",
    "    consecutive_fire_frames = 0\n",
    "    alarm_threshold = 3\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Perform fire detection every 3 seconds\n",
    "        if cap.get(cv2.CAP_PROP_POS_FRAMES) % frame_interval == 0:\n",
    "            img = cv2.resize(frame, (150, 150))\n",
    "            prediction = predict_image(model, img)\n",
    "\n",
    "            if prediction > 0.5:\n",
    "                consecutive_fire_frames += 1\n",
    "            else:\n",
    "                consecutive_fire_frames = 0\n",
    "\n",
    "            # Trigger alarm or print message if fire is detected continuously in 3 frames\n",
    "            if consecutive_fire_frames == alarm_threshold:\n",
    "                print(\"Fire Caught - Emergency!\")\n",
    "                # You can trigger an alarm here\n",
    "\n",
    "        # Display the frame (you can remove this if not needed)\n",
    "        cv2.imshow('Frame', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = keras.models.load_model('fire.keras')\n",
    "\n",
    "# Specify the path to your video file\n",
    "video_path = 'fire2.mp4'\n",
    "\n",
    "# Process the video for fire detection\n",
    "process_video(video_path, loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf0b3fc-64e9-40c4-9c1a-17211b04ec88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Fire Caught - Emergency!\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict_image(model, img):\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize the pixel values\n",
    "    prediction = model.predict(img_array)\n",
    "    return prediction[0][0]\n",
    "\n",
    "def process_video(video_path, model):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Set the frame rate\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(fps * 3)  # Capture a frame every 3 seconds\n",
    "\n",
    "    consecutive_fire_frames = 0\n",
    "    alarm_threshold = 3\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Perform fire detection every 3 seconds\n",
    "        if cap.get(cv2.CAP_PROP_POS_FRAMES) % frame_interval == 0:\n",
    "            img = cv2.resize(frame, (150, 150))\n",
    "            prediction = predict_image(model, img)\n",
    "\n",
    "            if prediction > 0.5:\n",
    "                consecutive_fire_frames += 1\n",
    "                # Highlight the detected fire in the frame\n",
    "                frame = cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 255), 5)\n",
    "            else:\n",
    "                consecutive_fire_frames = 0\n",
    "\n",
    "            # Trigger alarm or print message if fire is detected continuously in 3 frames\n",
    "            if consecutive_fire_frames == alarm_threshold:\n",
    "                print(\"Fire Caught - Emergency!\")\n",
    "                # You can trigger an alarm here\n",
    "\n",
    "            # Display the frame with the fire detection result\n",
    "            cv2.imshow('Frame', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = keras.models.load_model('fire.keras')\n",
    "\n",
    "# Specify the path to your video file\n",
    "video_path = 'nkp.mp4'\n",
    "\n",
    "# Process the video for fire detection\n",
    "process_video(video_path, loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d10ea3f-fff5-44b7-b092-86dac7e1701d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Fire Caught - Emergency!\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict_image(model, img):\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize the pixel values\n",
    "    prediction = model.predict(img_array)\n",
    "    return prediction[0][0]\n",
    "\n",
    "def process_video(video_path, model):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Set the frame rate\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(fps * 3)  # Capture a frame every 3 seconds\n",
    "\n",
    "    consecutive_fire_frames = 0\n",
    "    alarm_threshold = 3\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Perform fire detection every 3 seconds\n",
    "        if cap.get(cv2.CAP_PROP_POS_FRAMES) % frame_interval == 0:\n",
    "            img = cv2.resize(frame, (150, 150))\n",
    "            prediction = predict_image(model, img)\n",
    "\n",
    "            if prediction > 0.5:\n",
    "                consecutive_fire_frames += 1\n",
    "                # Convert the image to grayscale for contour detection\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                # Apply threshold to highlight fire regions\n",
    "                _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)\n",
    "                # Find contours of the fire regions\n",
    "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                # Draw rectangles around the fire regions\n",
    "                for contour in contours:\n",
    "                    x, y, w, h = cv2.boundingRect(contour)\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "            else:\n",
    "                consecutive_fire_frames = 0\n",
    "\n",
    "            # Trigger alarm or print message if fire is detected continuously in 3 frames\n",
    "            if consecutive_fire_frames == alarm_threshold:\n",
    "                print(\"Fire Caught - Emergency!\")\n",
    "                # You can trigger an alarm here\n",
    "\n",
    "            # Display the frame with the fire detection result\n",
    "            cv2.imshow('Frame', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = keras.models.load_model('fire.keras')\n",
    "\n",
    "# Specify the path to your video file\n",
    "video_path = 'fire1.mp4'\n",
    "\n",
    "# Process the video for fire detection\n",
    "process_video(video_path, loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "724f3d5c-9c2c-4051-98a3-d577676e9e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Fire Caught - Emergency!\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict_image(model, img):\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize the pixel values\n",
    "    prediction = model.predict(img_array)\n",
    "    return prediction[0][0]\n",
    "\n",
    "def process_video(video_path, model):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Set the frame rate\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(fps * 3)  # Capture a frame every 3 seconds\n",
    "\n",
    "    consecutive_fire_frames = 0\n",
    "    alarm_threshold = 3\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Perform fire detection every 3 seconds\n",
    "        if cap.get(cv2.CAP_PROP_POS_FRAMES) % frame_interval == 0:\n",
    "            img = cv2.resize(frame, (150, 150))\n",
    "            prediction = predict_image(model, img)\n",
    "\n",
    "            if prediction > 0.5:\n",
    "                consecutive_fire_frames += 1\n",
    "                # Convert the image to grayscale for contour detection\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                # Apply threshold to highlight fire regions\n",
    "                _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)\n",
    "                # Find contours of the fire regions\n",
    "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                # Find the largest contour (assumed to be the fire)\n",
    "                largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "                # Draw a rectangle around the largest fire region\n",
    "                x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "            else:\n",
    "                consecutive_fire_frames = 0\n",
    "\n",
    "            # Trigger alarm or print message if fire is detected continuously in 3 frames\n",
    "            if consecutive_fire_frames == alarm_threshold:\n",
    "                print(\"Fire Caught - Emergency!\")\n",
    "                # You can trigger an alarm here\n",
    "\n",
    "            # Display the frame with the fire detection result\n",
    "            cv2.imshow('Frame', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = keras.models.load_model('fire.keras')\n",
    "\n",
    "# Specify the path to your video file\n",
    "video_path = 'fire4.mp4'\n",
    "\n",
    "# Process the video for fire detection\n",
    "process_video(video_path, loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e17d1036-1ea2-49e0-9211-f87e9f3248b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "WARNING:tensorflow:From C:\\Users\\TOM & JERRY\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\TOM & JERRY\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\TOM & JERRY\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\TOM & JERRY\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "0.9995948\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "0.99990505\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "0.9999399\n",
      "Fire Caught - Emergency!\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "0.9999795\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "0.99999404\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "0.9999768\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "0.9999883\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "0.99997556\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "0.99996555\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "0.99997216\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "0.9997218\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "0.99913603\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "0.9994196\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.9998847\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "0.9999214\n",
      "Fire Caught - Emergency!\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "0.9990441\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import pygame\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Initialize pygame mixer\n",
    "pygame.mixer.init()\n",
    "\n",
    "def play_alarm():\n",
    "    # Load the alarm sound (replace 'alarm.mp3' with the path to your MP3 file)\n",
    "    pygame.mixer.music.load('alarm1.mp3')\n",
    "    # Set the volume (0.0 to 1.0)\n",
    "    pygame.mixer.music.set_volume(1.0)\n",
    "    # Play the alarm sound\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "def predict_image(model, img):\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize the pixel values\n",
    "    prediction = model.predict(img_array)\n",
    "    return prediction[0][0]\n",
    "\n",
    "def process_video(video_path, model):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Set the frame rate\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(fps * 2)  # Capture a frame every 3 seconds\n",
    "\n",
    "    consecutive_fire_frames = 0\n",
    "    alarm_threshold = 3\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Perform fire detection every 3 seconds\n",
    "        if cap.get(cv2.CAP_PROP_POS_FRAMES) % frame_interval == 0:\n",
    "            img = cv2.resize(frame, (150, 150))\n",
    "            #img_array = image.img_to_array(img)\n",
    "            #img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize the pixel values\n",
    "        \n",
    "            # Get the model's prediction\n",
    "            #prediction = model.predict(img_array)\n",
    "            prediction = predict_image(model, img)\n",
    "\n",
    "            if prediction >0.999:\n",
    "                consecutive_fire_frames += 1\n",
    "                # Convert the image to grayscale for contour detection\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                # Apply threshold to highlight fire regions\n",
    "                _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)\n",
    "                # Find contours of the fire regions\n",
    "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                # Find the largest contour (assumed to be the fire)\n",
    "                largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "                # Draw a rectangle around the largest fire region\n",
    "                x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                print(prediction)\n",
    "\n",
    "            else:\n",
    "                consecutive_fire_frames = 0\n",
    "\n",
    "            # Trigger alarm or print message if fire is detected continuously in 3 frames\n",
    "            if consecutive_fire_frames == alarm_threshold:\n",
    "                print(\"Fire Caught - Emergency!\")\n",
    "                play_alarm()\n",
    "                # You can trigger an alarm here\n",
    "                \n",
    "\n",
    "            # Display the frame with the fire detection result\n",
    "            cv2.imshow('Frame', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = keras.models.load_model('fire.keras')\n",
    "\n",
    "# Specify the path to your video file\n",
    "video_path = 'fire5.mp4'\n",
    "\n",
    "# Process the video for fire detection\n",
    "process_video(video_path, loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d06460-b645-4b55-a7d0-7fd726647d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
